{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Keras Model to Tensorflow\n",
    "\n",
    "This notebooks show how to export a keras model to tensorflow.\n",
    "\n",
    "The Keras model has to use `tf` image dim ordering and `channels_last` image data format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "def create_yolov1_tiny_model(shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(16, (3, 3), strides=(1, 1), padding='same', input_shape=shape, name='image'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(layers.Conv2D(512, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "    model.add(layers.Conv2D(1024, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    model.add(layers.Conv2D(1024, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    model.add(layers.Conv2D(1024, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.Dense(4096))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(layers.Dense(1470, name='prediction'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('tf')\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "model = create_yolov1_tiny_model((448, 448, 3))\n",
    "model.load_weights('yolo-tiny_tf.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export tensorflow model\n",
    "\n",
    "https://aqibsaeed.github.io/2017-05-02-deploying-tensorflow-model-andorid-device-human-activity-recognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf-exports/yolo-tiny-v1.ckpt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# all new operations will be in test mode from now on\n",
    "K.set_learning_phase(0)\n",
    "# serialize the model and get its weights, for quick re-building\n",
    "config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "    \n",
    "# re-build a model where the learning phase is now hard-coded to 0\n",
    "new_model = models.Sequential.from_config(config)\n",
    "new_model.set_weights(weights)\n",
    "\n",
    "sess = K.get_session()\n",
    "\n",
    "export_base_path = 'tf-exports'\n",
    "protobuf_path = os.path.join(export_base_path, 'yolo-tiny-v1.pbtxt')\n",
    "checkpoint_path = os.path.join(export_base_path, 'yolo-tiny-v1.ckpt')\n",
    "\n",
    "tf.train.write_graph(sess.graph_def, '.', protobuf_path)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, save_path = checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf-exports/yolo-tiny-v1.ckpt\n",
      "INFO:tensorflow:Froze 24 variables.\n",
      "Converted 24 variables to const ops.\n",
      "149 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "input_node_name = 'image_input'\n",
    "output_node_name = 'prediction/BiasAdd'\n",
    "\n",
    "output_frozen_graph_name = os.path.join(export_base_path, 'frozen_yolo.pb')\n",
    "output_optimized_graph_name = os.path.join(export_base_path, 'optimized_yolo.pb')\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph = protobuf_path,  input_saver = '',\n",
    "             input_binary = False, input_checkpoint = checkpoint_path, output_node_names = output_node_name,\n",
    "             restore_op_name = 'save/restore_all', filename_tensor_name = 'save/Const:0',\n",
    "             output_graph = output_frozen_graph_name, clear_devices = True, initializer_nodes = '')\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "\n",
    "with tf.gfile.Open(output_frozen_graph_name, 'rb') as f:\n",
    "    data = f.read()\n",
    "    input_graph_def.ParseFromString(data)\n",
    "\n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "        input_graph_def,\n",
    "        [input_node_name], \n",
    "        [output_node_name],\n",
    "        tf.float32.as_datatype_enum)\n",
    "\n",
    "f = tf.gfile.FastGFile(output_optimized_graph_name, 'wb')\n",
    "f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test optimized graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "input_node_name = 'image_input'\n",
    "output_node_name = 'prediction/BiasAdd'\n",
    "export_base_path = 'tf-exports'\n",
    "output_optimized_graph_name = os.path.join(export_base_path, 'optimized_yolo.pb')\n",
    "\n",
    "image_path = '../images/test1.jpg'\n",
    "\n",
    "image = load_img(image_path, grayscale=False)\n",
    "original_image = np.array(image)\n",
    "resized_image = np.array(image.resize((448, 448)))\n",
    "\n",
    "batch = np.array(resized_image)\n",
    "batch = 2*(batch/255.) - 1\n",
    "batch = np.expand_dims(batch, axis=0)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "result = None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.gfile.FastGFile(output_optimized_graph_name, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "        \n",
    "        predict_op = sess.graph.get_tensor_by_name(output_node_name+':0')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        result = sess.run(predict_op, feed_dict={input_node_name+':0': batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_bounding_boxes(result, threshold = 0.17):\n",
    "    grid_size = 7\n",
    "    num_classes = 20\n",
    "    num_boxes_per_cell = 2\n",
    "\n",
    "    predictions = result[:grid_size * grid_size * num_classes]\n",
    "    assert len(predictions) == 980\n",
    "\n",
    "    confidences = result[len(predictions) : len(predictions) + grid_size * grid_size * num_boxes_per_cell]\n",
    "    assert len(confidences) == 98\n",
    "\n",
    "    coordinates = result[len(predictions) + len(confidences):]\n",
    "    assert len(coordinates) == 392\n",
    "\n",
    "    predictions = predictions.reshape([grid_size * grid_size, num_classes])\n",
    "    confidences = confidences.reshape([grid_size * grid_size, num_boxes_per_cell])\n",
    "    coordinates = coordinates.reshape([grid_size * grid_size, 2, 4])\n",
    "    \n",
    "    boxes = []\n",
    "\n",
    "    cell_dim = 1. / grid_size\n",
    "\n",
    "    for cell_i in range(grid_size * grid_size):\n",
    "        for box_i in range(num_boxes_per_cell):\n",
    "            grid_row = cell_i // grid_size\n",
    "            grid_column = cell_i % grid_size\n",
    "\n",
    "            x, y, width, height = coordinates[cell_i, box_i]\n",
    "\n",
    "            # We parametrize the bounding box x and y coordinates to be offsets of a particular grid cell location so they are also bounded between 0 and 1\n",
    "            x = (grid_column * cell_dim) + (x * cell_dim)\n",
    "            y = (grid_row * cell_dim) + (y * cell_dim)\n",
    "\n",
    "            # We normalize the bounding box width and height by the image width and height so that they fall between 0 and 1.        \n",
    "            # This should really be **2, but the original implementation uses **1.8. No idea why though...\n",
    "            width = width ** 1.8\n",
    "            height = height ** 1.8\n",
    "\n",
    "            box_confidence = confidences[cell_i, box_i]\n",
    "\n",
    "            highest_class_probability_index = np.argmax(predictions[cell_i])\n",
    "            highest_class_probability = predictions[cell_i, highest_class_probability_index]\n",
    "\n",
    "            class_confidence = box_confidence * highest_class_probability\n",
    "\n",
    "            if class_confidence >= threshold:\n",
    "                boxes.append(np.array([\n",
    "                    x-(width/2), y-(height/2.), x+(width/2), y+(height/2.),\n",
    "                    class_confidence, highest_class_probability_index]))\n",
    "                \n",
    "    return np.array(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66604502  0.56738724  0.7532978   0.6752635   0.27005661  6.        ]\n",
      " [ 0.61987297  0.56078984  0.72358974  0.66884433  0.18670553  6.        ]\n",
      " [ 0.73898346  0.57076998  0.88162719  0.68145153  0.17469482  6.        ]\n",
      " [ 0.82350618  0.53657592  0.98578769  0.72717982  0.42168346  6.        ]]\n"
     ]
    }
   ],
   "source": [
    "boxes = to_bounding_boxes(result[0], threshold=0.17)\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export summary for tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "output_log_dir = os.path.join(export_base_path, 'logs')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model_filename = output_optimized_graph_name\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        g_in = tf.import_graph_def(graph_def)\n",
    "\n",
    "train_writer = tf.summary.FileWriter(output_log_dir)\n",
    "train_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `tensorboard --logdir=tf-exports/logs` to visualize the graph structure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
